{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix as dm\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "import random as ran\n",
    "import math as math\n",
    "import argparse\n",
    "\n",
    "def read_and_convert_data_points(filename):\n",
    "    \"\"\"\n",
    "    read_and_convert_data_points is a function that takes  a text file\n",
    "    as an argument and converts it into an array containing all the data points.\n",
    "    ==============================================================\n",
    "    :param filename: text file name in directory.\n",
    "    :return: npts x 2 array.\n",
    "    ==============================================================\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "    with open(filename, 'r') as f:\n",
    "        data_points = f.readlines()\n",
    "    \n",
    "    for data_point in data_points:\n",
    "        splits.append(data_point.split())\n",
    "    \n",
    "    return np.array(splits, dtype=np.float)\n",
    "\n",
    "def scatter_plot(data, output_file_name='none',i=0):\n",
    "    \"\"\"\n",
    "    scatter_plot is a function that plots the data and differentiate up to\n",
    "    two clusters.\n",
    "    ==============================================================\n",
    "    :param data: npts x 2, data set array.\n",
    "    :param output_file_name: \n",
    "    :param i: idx of the first data-point of the second cluster.\n",
    "    :return:\n",
    "    ==============================================================\n",
    "    \"\"\"\n",
    "    if i != 0:\n",
    "        x_1, y_1 = data[0:i].T\n",
    "        x_2, y_2 = data[i:data.shape[0]].T\n",
    "        plt.scatter(x_1, y_1, color='r')\n",
    "        plt.scatter(x_2, y_2, color = 'g')\n",
    "        \n",
    "        if output_file_name =='none': \n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(output_file_name)\n",
    "            plt.show() \n",
    "    else:\n",
    "        x, y = data.T\n",
    "        plt.scatter(x,y)\n",
    "        if output_file_name =='none': \n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.savefig(output_file_name)\n",
    "            plt.show()    \n",
    "\n",
    "def initial_clustering_membership_probability(clusters_number, npts):\n",
    "    \"\"\"\n",
    "    initial_clustering_membership_probability is a function that takes\n",
    "    as an argument the number of clusters 'C' and generates a random \n",
    "    cluster membership probability per element 'i'\n",
    "    in the data set composed by 'N'elements.\n",
    "    The sum of an element cluster membership probabilities is be 1.\n",
    "    ==============================================================\n",
    "    :param clusters_number: 'C'\n",
    "    :param npts: Number of data points in the data set.\n",
    "    :return initial_cond_prob: C x N matrix.\n",
    "    ==============================================================\n",
    "    \"\"\" \n",
    "    initial_cond_prob = np.zeros((npts,clusters_number))\n",
    "    for i in range(npts):\n",
    "        x = np.random.rand(clusters_number)\n",
    "        initial_cond_prob[i] = x/np.sum(x)\n",
    "    return initial_cond_prob.transpose()\n",
    "\n",
    "\n",
    "def blahut_arimoto_algorithm_imp(clusters_number,\n",
    "                              priors,\n",
    "                              distance_matrix,\n",
    "                              beta,\n",
    "                              npts_,\n",
    "                              rounds_,\n",
    "                              threshold=1e-10,\n",
    "                             ):\n",
    "    \"\"\"\n",
    "    the blahut_algorithm_imp function implements the Blahut Arimoto Algorithm \n",
    "    for a given number of clusters and a given value of beta.\n",
    "    For each round it will:\n",
    "    *firstly initialize the clustering membership probabilities randomly,\n",
    "    *compute the evidence for each cluster 'C'(returns a vector), \n",
    "    *Compute the posterior probability per cluster: returns a matrix C x Npts\n",
    "    *Compute the element to cluster distance: returns a matrix Npts x C\n",
    "    After performing all the previous operations for all clusters 'C' the \n",
    "    normalization (partition) function is created and posteriori to this the \n",
    "    clustering membership probabilities are updated. The function will later try\n",
    "    to minimize the Lagrange multiplier function until convergence i.e, there is no\n",
    "    improvement or the improvement is less than the threshold. When the function\n",
    "    reaches this condition it gets out of the loop and starts the next round.\n",
    "    \n",
    "    ==============================================================\n",
    "    :param clusters_number: \n",
    "    :param priors: prior probability for each data point, if uniformly \n",
    "    distributed = 1/Npts\n",
    "    :param distance_matrix: Matrix containing the distance from every vector in x \n",
    "    to every vector in y.\n",
    "    :param beta: distortion trade-off parameter\n",
    "    :param npts_: Number of data points in the data set.\n",
    "    :param rounds_: number on rounds (iterations) perform for averaging results.\n",
    "    :param threshold: if the minimization of the lagrange multiplier result \n",
    "    compared to the previous iteration's result is less than the threshold \n",
    "    the round will exit the loop.\n",
    "    :returns: scalar value, mean of the expected distortion for each round.\n",
    "    ==============================================================\n",
    "    \"\"\"\n",
    "\n",
    "    d_results=[]\n",
    "     \n",
    "    for round_number in range(rounds_):\n",
    "        d_ = []\n",
    "        lagrange_multiplier=[]\n",
    "        diff_elem_value=1\n",
    "        membership_prob = initial_clustering_membership_probability(\n",
    "                                                            clusters_number, npts_\n",
    "                                                                    )\n",
    "        evidence_vector = np.zeros((clusters_number,))\n",
    "        posteriori_prob = np.zeros((npts_, clusters_number)).transpose()\n",
    "        element_cluster_distance_matrix = np.zeros((npts_, clusters_number))\n",
    "\n",
    "        while diff_elem_value > threshold:\n",
    "  \n",
    "            for c in range(clusters_number):\n",
    "\n",
    "            #     Computes the evidence for each cluster 'C': returns a vector   \n",
    "                evidence_vector[c] = np.sum(np.dot(membership_prob[c], priors))\n",
    "            #     Computes the posterior probability: returns a matrix C x npts\n",
    "                posteriori_prob[c] = (np.dot(\n",
    "                                            priors, \n",
    "                                            membership_prob[c]\n",
    "                                            ))/evidence_vector[c]\n",
    "\n",
    "            #     Compute element to cluster distance:\n",
    "                element_cluster_distance_matrix.transpose()[c] =(\n",
    "\n",
    "                                                np.multiply(\n",
    "                                                    posteriori_prob[c], distance_matrix\n",
    "                                                           )\n",
    "                                                ).sum(axis=1,dtype='float')\n",
    "            #compute partition function:\n",
    "            exponential_beta_matrix = np.exp(-beta * element_cluster_distance_matrix)\n",
    "            normalization_partition_function = (\n",
    "                                np.multiply(evidence_vector,\n",
    "                                            exponential_beta_matrix\n",
    "                                            )).sum(axis=1)\n",
    "\n",
    "            #update conditional cluster_probability\n",
    "            membership_prob = (np.multiply\n",
    "                                (evidence_vector, \n",
    "                                 exponential_beta_matrix\n",
    "                                )/ normalization_partition_function[:,None]\n",
    "                               ).transpose()\n",
    "\n",
    "            #Compute averaged element to cluster distance:\n",
    "            joint_probability = np.multiply(evidence_vector, posteriori_prob.transpose())\n",
    "            d =np.sum(np.multiply(joint_probability,element_cluster_distance_matrix))\n",
    "\n",
    "            d_.append(d)\n",
    "            ##Compute Compression rate:       \n",
    "            ratios = posteriori_prob.transpose()/priors\n",
    "            compression_rate_ = np.sum(np.multiply(joint_probability, np.log2(ratios)))\n",
    "\n",
    "            ##Compute Lagrange Multiplier:\n",
    "            lagrange_multiplier_ = compression_rate_ + beta*d\n",
    "            lagrange_multiplier.append(lagrange_multiplier_)     \n",
    "\n",
    "            if len(lagrange_multiplier) > 1:\n",
    "                diff_elem_value = lagrange_multiplier[-2]-lagrange_multiplier[-1]\n",
    "\n",
    "        d_results.append(d_[-1])\n",
    "    return sum(d_results)/float(rounds_)\n",
    "\n",
    "\n",
    "def batch_perform_algorithm(\n",
    "                            range_betas_,\n",
    "                            prior_, \n",
    "                            distance_matrix, \n",
    "                            npts_,\n",
    "                            rounds_, \n",
    "                            range_clusters=range(2, 5)\n",
    "                            ):\n",
    "    \"\"\"\n",
    "    batch_perform_algorithm will recursively call the \n",
    "    blahut_arimoto_algorithm_imp function for a number of clusters and\n",
    "    distortion trade-off values (beta) it will return the coordinates \n",
    "    of the value that minimizes the expected distortion for a given \n",
    "    distortion trade-off. \n",
    "    ==============================================================\n",
    "    :param range_betas_:range of betas = list of the given betas \n",
    "    (distortion trade-off values) \n",
    "    that want to be evaluated.\n",
    "    :param prior_: prior probability for each data point, \n",
    "    if uniformly distributed = 1/npts\n",
    "    :param distance_matrix: Matrix containing the distance f\n",
    "    rom every vector in x to every vector in y.\n",
    "    :param npts_: Number of data points in the data set.\n",
    "    :param rounds_: number on rounds (iterations) perform for averaging results.\n",
    "    :param range_clusters: range of clusters = list of the given range.\n",
    "    ==============================================================\n",
    "    \"\"\"\n",
    "    results = np.zeros((len(range_clusters),len(range_betas_)))\n",
    "    betas=np.zeros((len(range_betas_)))\n",
    "    coordinates = np.zeros((len(range_clusters), len(range_betas_),2))\n",
    "    \n",
    "    for idx, cluster_n in enumerate(range_clusters):\n",
    "        for idx_beta, beta in enumerate(range_betas_):\n",
    "            results[idx, idx_beta] = blahut_arimoto_algorithm_imp(\n",
    "                                                                cluster_n,\n",
    "                                                                prior_,\n",
    "                                                                distance_matrix,\n",
    "                                                                beta,npts_,\n",
    "                                                                rounds_\n",
    "                                                                        )\n",
    "            betas[idx_beta]=beta\n",
    "    \n",
    "    for idx, cluster in enumerate(range_clusters):\n",
    "        coordinates[idx].transpose()[0] = (-results[idx])\n",
    "        coordinates[idx].transpose()[1] = betas\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "def plot_batch_information_curve(\n",
    "                                coordinates_,\n",
    "                                range_clusters=range(2, 5),\n",
    "                                out_filename='none'\n",
    "                                ):\n",
    "    \"\"\"\n",
    "    plot_batch_information_curve generates a plot with the given \n",
    "    coordinates, where the x axis is the value of the distortion trade-off\n",
    "    parameter and the y axis the (negative) expected distortion.\n",
    "    ==============================================================\n",
    "    :param coordinates_: output of batch_perform_algorithm function,\n",
    "    (C, Beta, 2) array.\n",
    "    :param range_clusters: range of clusters = list of the given range\n",
    "    :return: information curves plot\n",
    "    ==============================================================\n",
    "    \"\"\"\n",
    "    colors = [\n",
    "        '#e6194b', '#3cb44b', '#ffe119', '#4363d8', \n",
    "        '#f58231','#911eb4', '#46f0f0', '#f032e6', \n",
    "        '#bcf60c','#fabebe', '#008080', '#e6beff', \n",
    "        '#9a6324', '#fffac8', '#800000', '#aaffc3', \n",
    "        '#808000', '#ffd8b1', '#000075', '#808080', \n",
    "        '#ffffff', '#000000']\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    for i_coord, i_cluster in zip(range(coordinates_.shape[0]), range_clusters):\n",
    "        y,x = coordinates_[i_coord].T\n",
    "        plt.plot(x, y, marker='o', linestyle='--', \n",
    "                 color=colors[i_coord], \n",
    "                 label= f'Nc:{i_cluster}')    \n",
    "    plt.title('Information Curve')\n",
    "    plt.xlabel(r'$\\beta$')\n",
    "    plt.ylabel(r'$<-D>$')\n",
    "    plt.legend(loc='best')\n",
    "    if out_filename=='none':\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(out_filename)\n",
    "        plt.show() \n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function of the program\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Blahut-Arimoto Algorithm\")\n",
    "\n",
    "    parser.add_argument(\"-i\", \"--input\", metavar=\"INPUT_FILE\",\n",
    "                        help=\"Input file, Blast output file in xml format\")\n",
    "    parser.add_argument(\"-o\", \"--output\", metavar=\"OUTPUT_PLOT_FILE\",\n",
    "                        help=\"Output information curve plot file in PNG format.\",\n",
    "                        default=\"none\")\n",
    "    parser.add_argument(\"-c\", \"--clusters\", metavar=\"CLUSTERS_RANGE\",\n",
    "                        help=\"Clusters range, (2,5) if not specified\", \n",
    "                        default=range(2,5))\n",
    "    parser.add_argument(\"-b\", \"--betas\", metavar=\"BETAS_RANGE\",\n",
    "                        help=\"Betas range, range(1,55,5) if not specified\",\n",
    "                        default= [1,5,10,15,20,25,30,35,40,45,50])\n",
    "    parser.add_argument(\"-r\", \"--rounds\", metavar=\"NUMBER_OF_ROUNDS\",\n",
    "                        help=\"Number of rounds the algorithm will be executed,\n",
    "                        default=20)\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    data_points = read_and_convert_data_points(args.input)\n",
    "    npts, Ndim = data_points.shape\n",
    "    range_clusters = (range(2,5) if not args.clusters else args.clusters)\n",
    "    range_betas = ([1,5,10,15,20,25,30,35,40,45,50] if not args.betas else args.betas)\n",
    "    rounds_number = (20 if not args.rounds else args.rounds)\n",
    "    prior = 1 / float(npts)\n",
    "    distance_matrix_ = dm(data_points, data_points)\n",
    "    plot_batch_information_curve(batch_perform_algorithm(\n",
    "                                                        range_betas,\n",
    "                                                        prior,\n",
    "                                                        distance_matrix_,\n",
    "                                                        npts, rounds_number),\n",
    "                                                        range_clusters,\n",
    "                                                        out_filename=args.output\n",
    "                                                        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
